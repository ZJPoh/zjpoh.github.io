---
title: "Readings"
date: 2023-05-09
permalink: /posts/2023/05/readings
excerpt: "This is where I keep my reading lists"
tags:
  - ml
  - papers
---

# Forecasting
* Lim, Bryan, et al. "Temporal fusion transformers for interpretable multi-horizon time series forecasting." International Journal of Forecasting 37.4 (2021): 1748-1764. <https://arxiv.org/abs/1912.09363>
* Zhou, Tian, et al. "Fedformer: Frequency enhanced decomposed transformer for long-term series forecasting." International Conference on Machine Learning. PMLR, 2022. <https://arxiv.org/abs/2201.12740>
* Nie, Yuqi, et al. "A Time Series is Worth 64 Words: Long-term Forecasting with Transformers." arXiv preprint arXiv:2211.14730 (2022). <https://arxiv.org/abs/2211.14730>
* Das, Abhimanyu, et al. "Long-term Forecasting with TiDE: Time-series Dense Encoder." arXiv preprint arXiv:2304.08424 (2023). <https://arxiv.org/abs/2304.08424>
*

# Generic ML
* Shazeer, Noam, et al. "Outrageously large neural networks: The sparsely-gated mixture-of-experts layer." arXiv preprint arXiv:1701.06538 (2017). <https://arxiv.org/abs/1701.06538>
  * Sparsely gated to control for computation. Only use top-k experts.
  * Address computation challenges.
  * Need to balance experts to avoid favored experts being trained more.
* Brown, Tom, et al. "Language models are few-shot learners." Advances in neural information processing systems 33 (2020): 1877-1901. <https://arxiv.org/abs/2005.14165>
* Fedus, William, Barret Zoph, and Noam Shazeer. "Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity." The Journal of Machine Learning Research 23.1 (2022): 5232-5270. <https://arxiv.org/abs/2101.03961>
* Chowdhery, Aakanksha, et al. "Palm: Scaling language modeling with pathways." arXiv preprint arXiv:2204.02311 (2022). <https://arxiv.org/abs/2204.02311>
* Zhou, Yanqi, et al. "Mixture-of-experts with expert choice routing." Advances in Neural Information Processing Systems 35 (2022): 7103-7114. <https://arxiv.org/abs/2202.09368>
* 

* Balestriero, Randall, et al. "A Cookbook of Self-Supervised Learning." arXiv preprint arXiv:2304.12210 (2023). <https://arxiv.org/abs/2304.12210>

